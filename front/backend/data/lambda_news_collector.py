import json
import requests
import os
from datetime import datetime
import boto3
from botocore.exceptions import ClientError
import uuid
from bs4 import BeautifulSoup
import re
from urllib.parse import urlparse
import hashlib

def lambda_handler(event, context):
    """
    AWS Lambda í•¨ìˆ˜: ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° DynamoDB ì €ì¥
    """
    
    # ë„¤ì´ë²„ API ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    NAVER_CLIENT_ID = os.environ.get('NAVER_CLIENT_ID')
    NAVER_CLIENT_SECRET = os.environ.get('NAVER_CLIENT_SECRET')
    
    # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        print("âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return {
            'statusCode': 500,
            'body': {
                'message': 'í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜¤ë¥˜',
                'error': 'NAVER_CLIENT_ID ë˜ëŠ” NAVER_CLIENT_SECRETê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }
        }
    
    # DynamoDB ì„¤ì • (ì˜¤ì‚¬ì¹´ ë¦¬ì „)
    dynamodb = boto3.resource('dynamodb', region_name='ap-northeast-3')
    table = dynamodb.Table('ioi_contents_table')
    
    # S3 ì„¤ì • (ì˜¤ì‚¬ì¹´ ë¦¬ì „)
    s3_client = boto3.client('s3', region_name='ap-northeast-3')
    S3_BUCKET = 'ioi-contents-bukket'
    
    # CloudFront ë„ë©”ì¸ 
    CLOUDFRONT_DOMAIN = os.environ.get('CLOUDFRONT_DOMAIN', 'https://d3nvut5aamy17o.cloudfront.net')
    
    print(f"ğŸ”§ ì„¤ì • í™•ì¸:")
    print(f"  - S3 ë²„í‚·: {S3_BUCKET}")
    print(f"  - CloudFront ë„ë©”ì¸: {CLOUDFRONT_DOMAIN}")
    print(f"  - DynamoDB í…Œì´ë¸”: ioi_contents_table")
    print(f"  - ë¦¬ì „: ap-northeast-3 (ì˜¤ì‚¬ì¹´)")
    
    # ê²€ìƒ‰í•  í‚¤ì›Œë“œë“¤
    keywords = [
        "ë¹„íŠ¸ì½”ì¸"
    ]
    
    # ê²°ê³¼ ì €ì¥ìš©
    collected_news = []
    
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ API URL
    url = "https://openapi.naver.com/v1/search/news.json"
    
    # ìš”ì²­ í—¤ë”
    headers = {
        'X-Naver-Client-Id': NAVER_CLIENT_ID,
        'X-Naver-Client-Secret': NAVER_CLIENT_SECRET,
        'Content-Type': 'application/json'
    }
    
    print(f"=== ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ ===")
    print(f"ìˆ˜ì§‘ ì‹œê°„: {datetime.now().isoformat()}")
    print(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")
    
    total_collected = 0
    
    for keyword in keywords:
        print(f"\n--- '{keyword}' í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ---")
        
        # ìš”ì²­ íŒŒë¼ë¯¸í„°
        params = {
            'query': keyword,
            'display': 50,  # 10ê°œì”© ìˆ˜ì§‘
            'start': 1,
            'sort': 'date'  # ìµœì‹ ìˆœ
        }
        
        try:
            # API ìš”ì²­
            response = requests.get(url, params=params, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                items = data.get('items', [])
                
                print(f"'{keyword}': {len(items)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ë¨")
                
                # ë‰´ìŠ¤ ë°ì´í„° ì •ë¦¬ ë° DynamoDB ì €ì¥
                for item in items:
                    # ë‚ ì§œ ê¸°ë°˜ uid ìƒì„± (ì†ŒíŒ…ìš©)
                    now = datetime.now()
                    uid = now.strftime('%Y%m%d_%H%M%S_') + str(uuid.uuid4())[:8]
                    
                    # HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
                    def clean_html_tags(text):
                        import re
                        clean = re.compile('<.*?>')
                        return re.sub(clean, '', text)
                    
                    # ì›ë³¸ ë§í¬ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ ë° S3 ì—…ë¡œë“œ
                    original_link = item.get('originallink', '')
                    image_data = None
                    cloudfront_url = None
                    s3_key = None
                    
                    if original_link:
                        print(f"  ğŸ“¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œë„: {original_link}")
                        extracted_image_url = extract_image_from_article(original_link)
                        
                        if extracted_image_url:
                            print(f"  âœ“ ì´ë¯¸ì§€ URL ì¶”ì¶œ ì„±ê³µ: {extracted_image_url}")
                            
                            # S3ì— ì´ë¯¸ì§€ ì—…ë¡œë“œ
                            print(f"  ğŸ“¤ S3 ì—…ë¡œë“œ ì‹œë„...")
                            image_data = download_and_upload_image_to_s3(
                                extracted_image_url, 
                                uid, 
                                s3_client, 
                                S3_BUCKET, 
                                CLOUDFRONT_DOMAIN
                            )
                            
                            if image_data:
                                cloudfront_url = image_data['cloudfront_url']
                                s3_key = image_data['s3_key']
                                print(f"  âœ“ S3 ì—…ë¡œë“œ ì„±ê³µ!")
                                print(f"  ğŸŒ CloudFront URL: {cloudfront_url}")
                            else:
                                print(f"  âœ— S3 ì—…ë¡œë“œ ì‹¤íŒ¨")
                        else:
                            print(f"  âœ— ì´ë¯¸ì§€ URL ì¶”ì¶œ ì‹¤íŒ¨")
                    
                    news_item = {
                        'uid': uid,  # íŒŒí‹°ì…˜ í‚¤
                        'id': str(uuid.uuid4()),  # ì¶”ê°€ ê³ ìœ  ID
                        'keyword': keyword,
                        'title': clean_html_tags(item.get('title', '')),
                        'originallink': original_link,
                        'link': item.get('link', ''),
                        'description': clean_html_tags(item.get('description', '')),
                        'pubDate': item.get('pubDate', ''),
                        'image_url': cloudfront_url,  # CloudFront URL
                        's3_key': s3_key,  # S3 ê²½ë¡œ
                        'original_image_url': image_data['original_url'] if image_data else None,  # ì›ë³¸ ì´ë¯¸ì§€ URL
                        'collected_at': datetime.now().isoformat(),
                        'content_type': 'news',
                        'source': 'naver_api'
                    }
                    
                    # DynamoDBì— ì €ì¥
                    try:
                        table.put_item(Item=news_item)
                        print(f"  âœ“ DynamoDB ì €ì¥ ì„±ê³µ: {news_item['title'][:30]}...")
                        if cloudfront_url:
                            print(f"    ğŸ“¸ CloudFront URL í¬í•¨ë¨: {cloudfront_url}")
                        if s3_key:
                            print(f"    ğŸ“ S3 ê²½ë¡œ: {s3_key}")
                    except ClientError as e:
                        print(f"  âœ— DynamoDB ì €ì¥ ì‹¤íŒ¨: {e.response['Error']['Message']}")
                        continue
                    
                    collected_news.append(news_item)
                    total_collected += 1
                    
                    # ë¡œê·¸ì— ë‰´ìŠ¤ ì •ë³´ ì¶œë ¥
                    print(f"  - {news_item['title'][:50]}...")
                    
            else:
                print(f"API ì˜¤ë¥˜ ({keyword}): {response.status_code} - {response.text}")
                
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ ({keyword}): {str(e)}")
        
        # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ëŒ€ê¸°
        import time
        time.sleep(1)
    
    print(f"\n=== ìˆ˜ì§‘ ì™„ë£Œ ===")
    print(f"ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {total_collected}ê°œ")
    print(f"ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ: {len(keywords)}ê°œ")
    print(f"DynamoDB í…Œì´ë¸”: ioi_contents_table (ì˜¤ì‚¬ì¹´ ë¦¬ì „)")
    
    # ê²°ê³¼ ë°˜í™˜
    result = {
        'statusCode': 200,
        'body': {
            'message': 'ë‰´ìŠ¤ ìˆ˜ì§‘ ë° DynamoDB ì €ì¥ ì™„ë£Œ',
            'total_collected': total_collected,
            'keywords_searched': keywords,
            'collected_at': datetime.now().isoformat(),
            'dynamodb_table': 'ioi_contents_table',
            'dynamodb_region': 'ap-northeast-3',
            'sample_news': collected_news[:3] if collected_news else []  # ìƒ˜í”Œ 3ê°œë§Œ ë°˜í™˜
        }
    }
    
    # ì „ì²´ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ CloudWatch ë¡œê·¸ì— ì¶œë ¥
    print(f"\n=== ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ìƒì„¸ ì •ë³´ ===")
    for i, news in enumerate(collected_news, 1):
        print(f"\n[{i}] UID: {news['uid']}")
        print(f"    í‚¤ì›Œë“œ: {news['keyword']}")
        print(f"    ì œëª©: {news['title']}")
        print(f"    ë§í¬: {news['link']}")
        print(f"    ë°œí–‰ì¼: {news['pubDate']}")
        print(f"    ì´ë¯¸ì§€: {news.get('image_url', 'ì—†ìŒ')}")
        print(f"    S3 ê²½ë¡œ: {news.get('s3_key', 'ì—†ìŒ')}")
        print(f"    ì›ë³¸ ì´ë¯¸ì§€: {news.get('original_image_url', 'ì—†ìŒ')}")
        print(f"    ì„¤ëª…: {news['description'][:100]}...")
    
    return result

def download_and_upload_image_to_s3(image_url, uid, s3_client, bucket_name, cloudfront_domain):
    """
    ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ S3ì— ì—…ë¡œë“œí•˜ê³  CloudFront URL ë°˜í™˜
    """
    try:
        print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {image_url}")
        
        # User-Agent í—¤ë” ì¶”ê°€
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        response = requests.get(image_url, headers=headers, timeout=30, stream=True)
        response.raise_for_status()
        
        # ì½˜í…ì¸  íƒ€ì… í™•ì¸
        content_type = response.headers.get('content-type', '')
        if not content_type.startswith('image/'):
            print(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ íƒ€ì…: {content_type}")
            return None
        
        # íŒŒì¼ í™•ì¥ì ê²°ì •
        if 'jpeg' in content_type or 'jpg' in content_type:
            ext = '.jpg'
        elif 'png' in content_type:
            ext = '.png'
        elif 'gif' in content_type:
            ext = '.gif'
        elif 'webp' in content_type:
            ext = '.webp'
        else:
            # URLì—ì„œ í™•ì¥ì ì¶”ì¶œ ì‹œë„
            parsed_url = urlparse(image_url)
            path = parsed_url.path.lower()
            if any(path.endswith(e) for e in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                ext = '.' + path.split('.')[-1]
            else:
                ext = '.jpg'  # ê¸°ë³¸ê°’
        
        # S3 í‚¤ ìƒì„±: {uid}/images/ì´ë¯¸ì§€íŒŒì¼ëª…
        # ì´ë¯¸ì§€ URLì„ í•´ì‹œí•˜ì—¬ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        image_hash = hashlib.md5(image_url.encode()).hexdigest()[:12]
        s3_key = f"{uid}/images/{image_hash}{ext}"
        
        # S3ì— ì—…ë¡œë“œ
        s3_client.put_object(
            Bucket=bucket_name,
            Key=s3_key,
            Body=response.content,
            ContentType=content_type,
            CacheControl='max-age=31536000',  # 1ë…„ ìºì‹œ
            Metadata={
                'original_url': image_url,
                'uploaded_at': datetime.now().isoformat()
            }
        )
        
        # CloudFront URL ìƒì„±
        cloudfront_url = f"{cloudfront_domain.rstrip('/')}/{s3_key}"
        
        print(f"S3 ì—…ë¡œë“œ ì„±ê³µ: s3://{bucket_name}/{s3_key}")
        print(f"CloudFront URL: {cloudfront_url}")
        
        return {
            's3_key': s3_key,
            'cloudfront_url': cloudfront_url,
            'original_url': image_url
        }
        
    except requests.RequestException as e:
        print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        if hasattr(e, 'response') and e.response is not None:
            print(f"   HTTP ìƒíƒœ ì½”ë“œ: {e.response.status_code}")
        return None
    except ClientError as e:
        error_code = e.response['Error']['Code']
        error_message = e.response['Error']['Message']
        print(f"âŒ S3 ì—…ë¡œë“œ ì˜¤ë¥˜ [{error_code}]: {error_message}")
        
        if error_code == 'AccessDenied':
            print(f"   ğŸ’¡ S3 ë²„í‚· '{bucket_name}' ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
        elif error_code == 'NoSuchBucket':
            print(f"   ğŸ’¡ S3 ë²„í‚· '{bucket_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        return None
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        print(f"   ì´ë¯¸ì§€ URL: {image_url}")
        return None

def extract_image_from_article(article_url):
    """
    ë‰´ìŠ¤ ê¸°ì‚¬ URLì—ì„œ ì´ë¯¸ì§€ URLì„ ì¶”ì¶œ
    """
    try:
        print(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œì‘: {article_url}")
        
        # User-Agent í—¤ë” ì¶”ê°€í•˜ì—¬ í¬ë¡¤ë§ ì°¨ë‹¨ ë°©ì§€
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # ê¸°ì‚¬ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
        response = requests.get(article_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ íŒ¨í„´)
        image_url = None
        
        # 1. ì¼ë°˜ì ì¸ ê¸°ì‚¬ ì´ë¯¸ì§€ íƒœê·¸ë“¤
        img_patterns = [
            # ì¼ë°˜ img íƒœê·¸
            soup.find('img', {'class': re.compile(r'.*article.*|.*news.*|.*content.*|.*photo.*')}),
            # ë©”íƒ€ íƒœê·¸ì˜ og:image
            soup.find('meta', {'property': 'og:image'}),
            # íŠ¸ìœ„í„° ì¹´ë“œ ì´ë¯¸ì§€
            soup.find('meta', {'name': 'twitter:image'}),
            # ì²« ë²ˆì§¸ ë³¸ë¬¸ ì´ë¯¸ì§€
            soup.find('div', {'class': re.compile(r'.*article.*|.*content.*|.*body.*')}).find('img') if soup.find('div', {'class': re.compile(r'.*article.*|.*content.*|.*body.*')}) else None,
            # ë‹¨ìˆœíˆ ì²« ë²ˆì§¸ img íƒœê·¸
            soup.find('img')
        ]
        
        for img_tag in img_patterns:
            if img_tag:
                if img_tag.name == 'img':
                    # img íƒœê·¸ì—ì„œ src ì¶”ì¶œ
                    src = img_tag.get('src') or img_tag.get('data-src')
                elif img_tag.name == 'meta':
                    # meta íƒœê·¸ì—ì„œ content ì¶”ì¶œ
                    src = img_tag.get('content')
                else:
                    continue
                
                if src:
                    # ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
                    if src.startswith('//'):
                        image_url = 'https:' + src
                    elif src.startswith('/'):
                        from urllib.parse import urljoin
                        image_url = urljoin(article_url, src)
                    elif src.startswith('http'):
                        image_url = src
                    
                    # ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸
                    if image_url and any(ext in image_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                        print(f"ì´ë¯¸ì§€ URL ì¶”ì¶œ ì„±ê³µ: {image_url}")
                        return image_url
        
        print(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {article_url}")
        return None
        
    except requests.RequestException as e:
        print(f"HTTP ìš”ì²­ ì˜¤ë¥˜: {str(e)}")
        return None
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None

def get_news_from_dynamodb(limit=10):
    """
    DynamoDBì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ (uid ê¸°ì¤€ ìµœì‹ ìˆœ)
    """
    try:
        dynamodb = boto3.resource('dynamodb', region_name='ap-northeast-3')
        table = dynamodb.Table('ioi_contents_table')
        
        # ìµœì‹  ë‰´ìŠ¤ë¶€í„° ì¡°íšŒ (uid ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ - ë‚ ì§œìˆœ ì •ë ¬)
        response = table.scan(
            Limit=limit,
            ProjectionExpression='uid, id, title, description, keyword, pubDate, collected_at, originallink, image_url, s3_key, original_image_url'
        )
        
        items = response.get('Items', [])
        
        # uid ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ - ë‚ ì§œê°€ ì•ì— ìˆì–´ì„œ ë‚´ë¦¼ì°¨ìˆœí•˜ë©´ ìµœì‹ ì´ ìœ„ë¡œ)
        sorted_items = sorted(items, key=lambda x: x.get('uid', ''), reverse=True)
        
        print(f"DynamoDBì—ì„œ {len(sorted_items)}ê°œ ë‰´ìŠ¤ ì¡°íšŒë¨ (uid ê¸°ì¤€ ì •ë ¬)")
        
        return {
            'statusCode': 200,
            'body': {
                'message': 'DynamoDB ë‰´ìŠ¤ ì¡°íšŒ ì„±ê³µ',
                'total_items': len(sorted_items),
                'news_items': sorted_items,
                'table_name': 'ioi_contents_table',
                'region': 'ap-northeast-3',
                'sort_key': 'uid (ë‚ ì§œ ê¸°ë°˜)'
            }
        }
        
    except ClientError as e:
        print(f"DynamoDB ì¡°íšŒ ì˜¤ë¥˜: {e.response['Error']['Message']}")
        return {
            'statusCode': 500,
            'body': {
                'message': 'DynamoDB ì¡°íšŒ ì‹¤íŒ¨',
                'error': e.response['Error']['Message']
            }
        }

def test_local():
    """ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜"""
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€ê²½)
    os.environ['NAVER_CLIENT_ID'] = "2GgDhd6gDxBt6S4lQ2DU"
    os.environ['NAVER_CLIENT_SECRET'] = "OUghVjqy34"
    # CloudFront ë„ë©”ì¸ ì„¤ì •
    os.environ['CLOUDFRONT_DOMAIN'] = "https://d3nvut5aamy17o.cloudfront.net"
    
    # í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸
    test_event = {
        'test': True,
        'keywords': ['IT']  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ITë§Œ
    }
    
    print("=== ë‰´ìŠ¤ ìˆ˜ì§‘ ë° DynamoDB ì €ì¥ í…ŒìŠ¤íŠ¸ ===")
    result = lambda_handler(test_event, None)
    print(f"\n=== ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("\n=== DynamoDB ì¡°íšŒ í…ŒìŠ¤íŠ¸ ===")
    read_result = get_news_from_dynamodb(5)
    print(json.dumps(read_result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    test_local() 